{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54451063",
   "metadata": {},
   "source": [
    "## Perform Different data visualization for 2d and 3d visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73eb0758",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('2d_3d_visualization_dataset.csv')\n",
    "df\n",
    "# Display the first few rows\n",
    "print(df.head())\n",
    "# Display the information about the dataset\n",
    "print(df.describe())\n",
    "# 2D Visualizations\n",
    "# Create scatter plots for pairs of features\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.scatterplot(x='Feature1', y='Feature2', data=df)\n",
    "plt.title('Feature1 vs. Feature2')\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.scatterplot(x='Feature1', y='Feature3', data=df)\n",
    "plt.title('Feature1 vs. Feature3')\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.scatterplot(x='Feature2', y='Feature3', data=df)\n",
    "plt.title('Feature2 vs. Feature3')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Create a correlation matrix heatmap\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Matrix')\n",
    "\n",
    "# 3D Visualization\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(df['Feature1'], df['Feature2'], df['Feature3'])\n",
    "ax.set_xlabel('Feature1')\n",
    "ax.set_ylabel('Feature2')\n",
    "ax.set_zlabel('Feature3')\n",
    "plt.title('3D Scatter Plot of Features')\n",
    "plt.legend()\n",
    "# plt.savefig('3d_scatter_plot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbba912",
   "metadata": {},
   "source": [
    "## Perform Regression over the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59831bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "df2 = pd.read_csv('simple_linear_regression_dataset.csv')\n",
    "df2\n",
    "\n",
    "df2.head()\n",
    "\n",
    "X = df2[['X']]  # independent variable\n",
    "y = df2['y']   # dependent variable\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "intercept = model.intercept_\n",
    "coefficient = model.coef_[0]\n",
    "\n",
    "print(f\"\\nModel Intercept: {intercept:.2f}\")\n",
    "print(f\"Model Coefficient (slope): {coefficient:.2f}\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# Visualize the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X, y, label='Actual Data')\n",
    "plt.plot(X, y_pred, color='red', linewidth=2, label='Regression Line')\n",
    "plt.title('Simple Linear Regression')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918f54e9",
   "metadata": {},
   "source": [
    "## To Perform Data collection from online, local drive and .csv file.\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408fc543",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "url=\"https://jsonplaceholder.typicode.com/posts\"\n",
    "response=requests.get(url)\n",
    "data_online=pd.DataFrame(response.json())\n",
    "print(data_online.head())\n",
    "\n",
    "#localdrive\n",
    "data_csv=pd.read_csv(\"candy-data.csv\")\n",
    "data_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f9fc3a",
   "metadata": {},
   "source": [
    "## Q4. Perform Classification of dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26487c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "feature_names = iris.feature_names\n",
    "\n",
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "df['target'] = y\n",
    "print(df.head())\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, target_names=iris.target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7faa5981",
   "metadata": {},
   "source": [
    "## Q5. Perform decision tree operation over the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e04187",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "dataset=pd.read_csv('play_tennis.csv')\n",
    "dataset\n",
    "\n",
    "Le=LabelEncoder()\n",
    "dataset['outlook']=Le.fit_transform(dataset['outlook'])\n",
    "dataset['temp']=Le.fit_transform(dataset['temp'])\n",
    "dataset['humidity']=Le.fit_transform(dataset['humidity'])\n",
    "dataset['wind']=Le.fit_transform(dataset['wind'])\n",
    "dataset['play']=Le.fit_transform(dataset['play'])\n",
    "\n",
    "x1=dataset.iloc[:,:-1].values\n",
    "y1=dataset.iloc[:,4].values\n",
    "\n",
    "from sklearn import tree\n",
    "clf=tree.DecisionTreeClassifier(criterion='entropy')\n",
    "clf=clf.fit(x1,y1)\n",
    "\n",
    "tree.plot_tree(clf)\n",
    "\n",
    "x_predict=clf.predict(x1)\n",
    "x_predict==y1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c04076",
   "metadata": {},
   "source": [
    "## Q6. Implement classical golf case for playing golf game or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374b8882",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "dataset2=pd.read_csv('play_tennis.csv')\n",
    "dataset2\n",
    "\n",
    "Le=LabelEncoder()\n",
    "dataset2['outlook']=Le.fit_transform(dataset['outlook'])\n",
    "dataset2['temp']=Le.fit_transform(dataset['temp'])\n",
    "dataset2['humidity']=Le.fit_transform(dataset['humidity'])\n",
    "dataset2['wind']=Le.fit_transform(dataset['wind'])\n",
    "dataset2['play']=Le.fit_transform(dataset['play'])\n",
    "\n",
    "X2=dataset2.drop('play',axis=1)\n",
    "y2=dataset2['play']\n",
    "\n",
    "#splitting the dataset\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X2, y2, test_size=0.2, random_state=42)\n",
    "\n",
    "#model building\n",
    "model = LogisticRegression()\n",
    "model.fit(X1_train, y1_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = model.predict(X1_test)\n",
    "\n",
    "#model Evaluation\n",
    "print(\"Accuracy:\", accuracy_score(y1_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y1_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y1_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4dfd15",
   "metadata": {},
   "source": [
    "## Q7. Create a small stock market analysis for bull or bear for a stock in NSE and BSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dc5b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yfp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Download stock data (NSE - RELIANCE)\n",
    "data = yf.download(\"RELIANCE.NS\", start=\"2024-01-01\", end=\"2024-12-31\")\n",
    "\n",
    "# Find daily return\n",
    "data['Return'] = data['Close'].pct_change()\n",
    "\n",
    "# Label Bull/Bear\n",
    "data['Trend'] = np.where(data['Return'] > 0, 'Bull', 'Bear')\n",
    "\n",
    "# Show last few rows\n",
    "print(data[['Close', 'Return', 'Trend']].tail())\n",
    "\n",
    "# Plot price\n",
    "data['Close'].plot(title=\"Reliance Stock Price (Bull/Bear)\", figsize=(10,5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0f39cd",
   "metadata": {},
   "source": [
    "## Q8. To Perform Data cleaning Operation over the data collected.\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c16beb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "\n",
    "data = load_breast_cancer()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target\n",
    "print(\"First 5 rows:\\n\", df.head())\n",
    "\n",
    "\n",
    "print(\"\\nMissing values:\\n\", df.isnull().sum())\n",
    "\n",
    "print(\"\\nNumber of duplicate rows:\", df.duplicated().sum())\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "for col in df.select_dtypes(include=[np.number]).columns:\n",
    "    lower, upper = df[col].quantile([0.01, 0.99])\n",
    "    df[col] = df[col].clip(lower, upper)\n",
    "\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
    "\n",
    "\n",
    "print(\"\\nSummary Statistics:\\n\", df.describe())\n",
    "\n",
    "print(\"\\nCleaned dataset shape:\", df.shape)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
